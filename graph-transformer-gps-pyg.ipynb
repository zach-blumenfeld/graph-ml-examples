{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zach-blumenfeld/graph-ml-examples/blob/main/graph-transformer-gps-pyg.ipynb)\n",
        "\n",
        "Based off of [this code example](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/graph_gps.py)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "U9CK9SK6CGRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.3.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.0\n"
          ]
        }
      ],
      "source": [
        "%pip install torch_geometric"
      ],
      "metadata": {
        "id": "BgQdjjVuCGRv",
        "outputId": "d37f61a9-428d-41d4-83c1-fdae5d51621a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os.path as osp\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "import torch\n",
        "from torch.nn import (\n",
        "    BatchNorm1d,\n",
        "    Embedding,\n",
        "    Linear,\n",
        "    ModuleList,\n",
        "    ReLU,\n",
        "    Sequential,\n",
        ")\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import ZINC\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GINEConv, GPSConv, global_add_pool\n",
        "from torch_geometric.nn.attention import PerformerAttention"
      ],
      "metadata": {
        "id": "y5Kq85saCGRv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.dropbox.com/s/feo9qle74kg48gy/molecules.zip?dl=1\n",
            "Extracting ./molecules.zip\n",
            "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/train.index\n",
            "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/val.index\n",
            "Downloading https://raw.githubusercontent.com/graphdeeplearning/benchmarking-gnns/master/data/molecules/test.index\n",
            "Processing...\n",
            "Processing train dataset: 100%|██████████| 10000/10000 [00:06<00:00, 1535.85it/s]\n",
            "Processing val dataset: 100%|██████████| 1000/1000 [00:00<00:00, 1249.39it/s]\n",
            "Processing test dataset: 100%|██████████| 1000/1000 [00:00<00:00, 1442.06it/s]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "transform = T.AddRandomWalkPE(walk_length=20, attr_name='pe')\n",
        "train_dataset = ZINC('.', subset=True, split='train', pre_transform=transform)\n",
        "val_dataset = ZINC('.', subset=True, split='val', pre_transform=transform)\n",
        "test_dataset = ZINC('.', subset=True, split='test', pre_transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "D7Kpc3noCGRw",
        "outputId": "290946e8-7097-41c8-98de-27e4131453e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "class RedrawProjection:\n",
        "    def __init__(self, model: torch.nn.Module,\n",
        "                 redraw_interval: Optional[int] = None):\n",
        "        self.model = model\n",
        "        self.redraw_interval = redraw_interval\n",
        "        self.num_last_redraw = 0\n",
        "\n",
        "    def redraw_projections(self):\n",
        "        if not self.model.training or self.redraw_interval is None:\n",
        "            return\n",
        "        if self.num_last_redraw >= self.redraw_interval:\n",
        "            fast_attentions = [\n",
        "                module for module in self.model.modules()\n",
        "                if isinstance(module, PerformerAttention)\n",
        "            ]\n",
        "            for fast_attention in fast_attentions:\n",
        "                fast_attention.redraw_projection_matrix()\n",
        "            self.num_last_redraw = 0\n",
        "            return\n",
        "        self.num_last_redraw += 1\n",
        "\n",
        "class GPS(torch.nn.Module):\n",
        "    def __init__(self, channels: int, pe_dim: int, num_layers: int,\n",
        "                 attn_type: str, attn_kwargs: Dict[str, Any]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.node_emb = Embedding(28, channels - pe_dim)\n",
        "        self.pe_lin = Linear(20, pe_dim)\n",
        "        self.pe_norm = BatchNorm1d(20)\n",
        "        self.edge_emb = Embedding(4, channels)\n",
        "\n",
        "        self.convs = ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            nn = Sequential(\n",
        "                Linear(channels, channels),\n",
        "                ReLU(),\n",
        "                Linear(channels, channels),\n",
        "            )\n",
        "            conv = GPSConv(channels, GINEConv(nn), heads=4,\n",
        "                           attn_type=attn_type, attn_kwargs=attn_kwargs)\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        self.mlp = Sequential(\n",
        "            Linear(channels, channels // 2),\n",
        "            ReLU(),\n",
        "            Linear(channels // 2, channels // 4),\n",
        "            ReLU(),\n",
        "            Linear(channels // 4, 1),\n",
        "        )\n",
        "        self.redraw_projection = RedrawProjection(\n",
        "            self.convs,\n",
        "            redraw_interval=1000 if attn_type == 'performer' else None)\n",
        "\n",
        "    def forward(self, x, pe, edge_index, edge_attr, batch):\n",
        "        x_pe = self.pe_norm(pe)\n",
        "        x = torch.cat((self.node_emb(x.squeeze(-1)), self.pe_lin(x_pe)), 1)\n",
        "        edge_attr = self.edge_emb(edge_attr)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index, batch, edge_attr=edge_attr)\n",
        "        x = global_add_pool(x, batch)\n",
        "        return self.mlp(x)"
      ],
      "metadata": {
        "id": "iIegrof2CGRw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 0.6875, Val: 0.4911, Test: 0.5251\n",
            "Epoch: 02, Loss: 0.5468, Val: 0.4072, Test: 0.4013\n",
            "Epoch: 03, Loss: 0.4700, Val: 0.4564, Test: 0.4476\n",
            "Epoch: 04, Loss: 0.4663, Val: 0.5213, Test: 0.5009\n",
            "Epoch: 05, Loss: 0.4458, Val: 0.3821, Test: 0.3792\n",
            "Epoch: 06, Loss: 0.4052, Val: 0.3914, Test: 0.4183\n",
            "Epoch: 07, Loss: 0.4277, Val: 0.3724, Test: 0.3445\n",
            "Epoch: 08, Loss: 0.3761, Val: 0.4707, Test: 0.4439\n",
            "Epoch: 09, Loss: 0.3823, Val: 0.3448, Test: 0.3016\n",
            "Epoch: 10, Loss: 0.3654, Val: 0.3727, Test: 0.3486\n",
            "Epoch: 11, Loss: 0.3628, Val: 0.5614, Test: 0.5008\n",
            "Epoch: 12, Loss: 0.3436, Val: 0.3257, Test: 0.2987\n",
            "Epoch: 13, Loss: 0.3450, Val: 0.3102, Test: 0.3114\n",
            "Epoch: 14, Loss: 0.3409, Val: 0.3398, Test: 0.3023\n",
            "Epoch: 15, Loss: 0.3447, Val: 0.3138, Test: 0.2813\n",
            "Epoch: 16, Loss: 0.3452, Val: 0.4588, Test: 0.4463\n",
            "Epoch: 17, Loss: 0.3265, Val: 0.3144, Test: 0.2898\n",
            "Epoch: 18, Loss: 0.3396, Val: 0.4102, Test: 0.3722\n",
            "Epoch: 19, Loss: 0.3226, Val: 0.4392, Test: 0.4152\n",
            "Epoch: 20, Loss: 0.3144, Val: 0.3578, Test: 0.3425\n",
            "Epoch: 21, Loss: 0.3191, Val: 0.4273, Test: 0.4043\n",
            "Epoch: 22, Loss: 0.2986, Val: 0.2677, Test: 0.2334\n",
            "Epoch: 23, Loss: 0.3328, Val: 0.3195, Test: 0.3210\n",
            "Epoch: 24, Loss: 0.3294, Val: 0.2618, Test: 0.2389\n",
            "Epoch: 25, Loss: 0.3004, Val: 0.2856, Test: 0.2583\n",
            "Epoch: 26, Loss: 0.2895, Val: 0.2666, Test: 0.2346\n",
            "Epoch: 27, Loss: 0.2839, Val: 0.2827, Test: 0.2723\n",
            "Epoch: 28, Loss: 0.2770, Val: 0.2898, Test: 0.2694\n",
            "Epoch: 29, Loss: 0.2714, Val: 0.2688, Test: 0.2277\n",
            "Epoch: 30, Loss: 0.2816, Val: 0.2273, Test: 0.2008\n",
            "Epoch: 31, Loss: 0.2814, Val: 0.3232, Test: 0.2926\n",
            "Epoch: 32, Loss: 0.2657, Val: 0.3348, Test: 0.3127\n",
            "Epoch: 33, Loss: 0.2660, Val: 0.2749, Test: 0.2455\n",
            "Epoch: 34, Loss: 0.2565, Val: 0.2271, Test: 0.2031\n",
            "Epoch: 35, Loss: 0.2484, Val: 0.2408, Test: 0.2275\n",
            "Epoch: 36, Loss: 0.2429, Val: 0.3137, Test: 0.2810\n",
            "Epoch: 37, Loss: 0.2351, Val: 0.2247, Test: 0.1949\n",
            "Epoch: 38, Loss: 0.2403, Val: 0.2849, Test: 0.2620\n",
            "Epoch: 39, Loss: 0.2373, Val: 0.2238, Test: 0.2110\n",
            "Epoch: 40, Loss: 0.2366, Val: 0.2232, Test: 0.1913\n",
            "Epoch: 41, Loss: 0.2303, Val: 0.2533, Test: 0.2196\n",
            "Epoch: 42, Loss: 0.2210, Val: 0.3110, Test: 0.2942\n",
            "Epoch: 43, Loss: 0.2272, Val: 0.2143, Test: 0.1842\n",
            "Epoch: 44, Loss: 0.2249, Val: 0.2217, Test: 0.1974\n",
            "Epoch: 45, Loss: 0.2210, Val: 0.2229, Test: 0.2007\n",
            "Epoch: 46, Loss: 0.2223, Val: 0.2236, Test: 0.2044\n",
            "Epoch: 47, Loss: 0.2226, Val: 0.2339, Test: 0.2094\n",
            "Epoch: 48, Loss: 0.2160, Val: 0.2486, Test: 0.2237\n",
            "Epoch: 49, Loss: 0.2082, Val: 0.2137, Test: 0.1822\n",
            "Epoch: 50, Loss: 0.2032, Val: 0.2087, Test: 0.1781\n",
            "Epoch: 51, Loss: 0.2049, Val: 0.2258, Test: 0.1846\n",
            "Epoch: 52, Loss: 0.2223, Val: 0.2400, Test: 0.2123\n",
            "Epoch: 53, Loss: 0.2163, Val: 0.2159, Test: 0.1899\n",
            "Epoch: 54, Loss: 0.2105, Val: 0.2126, Test: 0.1833\n",
            "Epoch: 55, Loss: 0.2028, Val: 0.2639, Test: 0.2474\n",
            "Epoch: 56, Loss: 0.2101, Val: 0.2260, Test: 0.2140\n",
            "Epoch: 57, Loss: 0.2067, Val: 0.2405, Test: 0.2202\n",
            "Epoch: 58, Loss: 0.2024, Val: 0.1967, Test: 0.1711\n",
            "Epoch: 59, Loss: 0.2017, Val: 0.1985, Test: 0.1675\n",
            "Epoch: 60, Loss: 0.1917, Val: 0.2156, Test: 0.1784\n",
            "Epoch: 61, Loss: 0.2047, Val: 0.2211, Test: 0.1861\n",
            "Epoch: 62, Loss: 0.2077, Val: 0.2263, Test: 0.1815\n",
            "Epoch: 63, Loss: 0.1977, Val: 0.2487, Test: 0.2217\n",
            "Epoch: 64, Loss: 0.2056, Val: 0.2265, Test: 0.1992\n",
            "Epoch: 65, Loss: 0.1928, Val: 0.2003, Test: 0.1670\n",
            "Epoch: 66, Loss: 0.1939, Val: 0.1892, Test: 0.1700\n",
            "Epoch: 67, Loss: 0.1843, Val: 0.1919, Test: 0.1642\n",
            "Epoch: 68, Loss: 0.1984, Val: 0.1948, Test: 0.1693\n",
            "Epoch: 69, Loss: 0.1888, Val: 0.1881, Test: 0.1600\n",
            "Epoch: 70, Loss: 0.1863, Val: 0.2107, Test: 0.1868\n",
            "Epoch: 71, Loss: 0.1781, Val: 0.1897, Test: 0.1638\n",
            "Epoch: 72, Loss: 0.1816, Val: 0.1796, Test: 0.1630\n",
            "Epoch: 73, Loss: 0.1828, Val: 0.2289, Test: 0.2021\n",
            "Epoch: 74, Loss: 0.1889, Val: 0.2163, Test: 0.1885\n",
            "Epoch: 75, Loss: 0.1841, Val: 0.2027, Test: 0.1857\n",
            "Epoch: 76, Loss: 0.1888, Val: 0.2319, Test: 0.2168\n",
            "Epoch: 77, Loss: 0.1831, Val: 0.1882, Test: 0.1681\n",
            "Epoch: 78, Loss: 0.1752, Val: 0.1688, Test: 0.1481\n",
            "Epoch: 79, Loss: 0.1814, Val: 0.1905, Test: 0.1775\n",
            "Epoch: 80, Loss: 0.1762, Val: 0.2120, Test: 0.1899\n",
            "Epoch: 81, Loss: 0.1750, Val: 0.2098, Test: 0.1838\n",
            "Epoch: 82, Loss: 0.1740, Val: 0.2137, Test: 0.1816\n",
            "Epoch: 83, Loss: 0.1671, Val: 0.1979, Test: 0.1750\n",
            "Epoch: 84, Loss: 0.1695, Val: 0.2367, Test: 0.2079\n",
            "Epoch: 85, Loss: 0.1840, Val: 0.2017, Test: 0.1760\n",
            "Epoch: 86, Loss: 0.1721, Val: 0.1945, Test: 0.1671\n",
            "Epoch: 87, Loss: 0.1700, Val: 0.1862, Test: 0.1802\n",
            "Epoch: 88, Loss: 0.1726, Val: 0.1746, Test: 0.1474\n",
            "Epoch: 89, Loss: 0.1737, Val: 0.1732, Test: 0.1581\n",
            "Epoch: 90, Loss: 0.1783, Val: 0.1970, Test: 0.1581\n",
            "Epoch: 91, Loss: 0.1817, Val: 0.1921, Test: 0.1535\n",
            "Epoch: 92, Loss: 0.1684, Val: 0.1822, Test: 0.1733\n",
            "Epoch: 93, Loss: 0.1612, Val: 0.1591, Test: 0.1401\n",
            "Epoch: 94, Loss: 0.1672, Val: 0.2194, Test: 0.1957\n",
            "Epoch: 95, Loss: 0.1646, Val: 0.2020, Test: 0.1977\n",
            "Epoch: 96, Loss: 0.1953, Val: 0.1784, Test: 0.1553\n",
            "Epoch: 97, Loss: 0.1658, Val: 0.1780, Test: 0.1473\n",
            "Epoch: 98, Loss: 0.1603, Val: 0.2049, Test: 0.1800\n",
            "Epoch: 99, Loss: 0.1739, Val: 0.1748, Test: 0.1508\n",
            "Epoch: 100, Loss: 0.1734, Val: 0.1795, Test: 0.1462\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "attn_kwargs = {'dropout': 0.5}\n",
        "model = GPS(channels=64, pe_dim=8, num_layers=10, attn_type='multihead',\n",
        "            attn_kwargs=attn_kwargs).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20,\n",
        "                              min_lr=0.00001)\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        model.redraw_projection.redraw_projections()\n",
        "        out = model(data.x, data.pe, data.edge_index, data.edge_attr,\n",
        "                    data.batch)\n",
        "        loss = (out.squeeze() - data.y).abs().mean()\n",
        "        loss.backward()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "\n",
        "    total_error = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.pe, data.edge_index, data.edge_attr,\n",
        "                    data.batch)\n",
        "        total_error += (out.squeeze() - data.y).abs().sum().item()\n",
        "    return total_error / len(loader.dataset)\n",
        "\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    val_mae = test(val_loader)\n",
        "    test_mae = test(test_loader)\n",
        "    scheduler.step(val_mae)\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_mae:.4f}, '\n",
        "          f'Test: {test_mae:.4f}')\n"
      ],
      "metadata": {
        "id": "WB7sD12gCGRw",
        "outputId": "cbb1ec09-17fb-4236-80be-3ece2d1d1b1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "BmUuAY-1CGRx"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}